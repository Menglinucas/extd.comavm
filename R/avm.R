#' @title avm modeling
#'
#' @description model fitting function
#' @param data.train data for fitting generated by \code{\link{avm.data.train}} or \code{\link{data.split}}
#' @param dependentY dependent variable. The default is 'K0'
#' @param independentX independent variables. Using var exception,see detail.
#' @param method ols? rlm? rft? svm? xgb?
#' @export
#' @return The list of AVM models
avm.fit<-function(data.train=NULL,dependentY='K0',independentX,method='ols'){
    if(is.null(data.train)){
        stop('must provide data.train!!!!')
    }
    # formula
    formula.lm.saleprice<-paste(dependentY,paste(independentX,collapse = '+'),sep='~')%>% as.formula
    # train.models structure
    # fit
    if(method=='ols'){
        # cat('trainning Linear Regression','\n')
        train.models<-train.ols(data.train,formula.lm.saleprice)
    }
    if(method=='rlm'){
        # cat('trainning Robust Linear Regression','\n')
        ols<-train.ols(data.train,formula.lm.saleprice)
        train.models<-train.rlm(data.train,formula(ols))
    }
    if(method=='svm'){
        # cat('trainning Support Vector Machine','\n')
        train.models<-train.svm(data.train,formula.lm.saleprice)
    }
    if(method=='rft'){
        # cat('trainning Random Forests','\n')
        train.models<-train.rft(data.train,formula.lm.saleprice,ntree=500)
    }
    # if(model.list$gwr){
    #     cat('trainning Geographically Weighted Regression','\n')
    #     train.models$gwr<-train.gwr(data.train,formula(train.models$ols),remove.dup=remove.dup)
    # }
    if(method=='xgb'){
        # cat('trainning eXtreme Gradient Boosting','\n')
        train.models<-train.xgb(data.train,formula.lm.saleprice,nround = 1000)
    }
    return(train.models)
}

#' @title Get the valid dependent variable
#' 
#' @description delete the independent variable that missing data is more than 40%
#' @param data relatively rough data sets
#' @param independentX independent variables. Using var exception,see detail.
#' @param min.missing.rate The rate of missing rate for keeping, The default is 0.4 which indicting when the rate of a feature is more than 40 percent, it will be removed from data
#' @export
#' @return vector of dependent variable names
formula_rvars <- function(data=NULL,
                      independentX='~.-ha_code-K0-Kbyear-Kheight-Ktime-Kfloor-KbrArea-Kstru-Kface_through-Kface_sun-Kdeco_if-Kdeco_good-Kprop_rt',
                      min.missing.rate=0.4){
  if(is.null(data)){
    stop('must provide data.train!!!!')
  }
  library(formula.tools)
  rvars<-rhs.vars(as.formula(independentX),data=data)
  for (i in 1:length(rvars)){
    if(mean(is.na(data[,rvars[i]]))>=min.missing.rate){
      # cat('removed ',rvars[i],' missing rate >=',min.missing.rate,'\n')
      data<-data%>%dplyr::select(-one_of(rvars[i]))
    }
  }
  rvars<-rhs.vars(as.formula(independentX),data=data)
  
  return(rvars)
}

train.ols<-function(data.train=NULL,formula=NULL){
    if(is.null(data.train)|is.null(formula)){
        stop('data or formula can not be NULL!!')
    }
    # rvars <- rhs.vars(formula)
    # rvars <- rvars[rvars!='bc11' & rvars!='bc12' & rvars!='bc13' & rvars!='bc21']
    # formula2 <- paste(lhs.vars(formula),paste(rvars,collapse = '+'),sep='~')%>% as.formula
    # model1 <- stats::lm(formula,data=data.train)
    # model2 <- step(stats::lm(formula2,data=data.train),trace=F)
    # if (AIC(model2)<AIC(model1)) {model1 <- model2}
    # return(model1)
    step(stats::lm(formula,data=data.train),trace=F)
}
pred.ols<-function(avm.ols=NULL,newdata=NULL){
    if(is.null(avm.ols)|is.null(newdata)){
        stop('model or newdata can not be NULL!!')
    }
    stats:::predict.lm(avm.ols,newdata=newdata)
}
train.rlm<-function(data.train=NULL,formula=NULL){
    if(is.null(data.train)|is.null(formula)){
        stop('data or formula can not be NULL!!')
    }
    suppressWarnings(MASS::rlm(formula,data=data.train))
}
pred.rlm<-function(avm.rlm=NULL,newdata=NULL){
    if(is.null(avm.rlm)|is.null(newdata)){
        stop('model or newdata can not be NULL!!')
    }
    library(MASS)
    predict(avm.rlm,data=newdata)
}
train.svm<-function(data.train=NULL,formula=NULL){
    if(is.null(data.train)|is.null(formula)){
        stop('data or formula can not be NULL!!')
    }
    e1071::svm(formula,data=data.train)
}
pred.svm<-function(avm.svm=NULL,newdata=NULL){
    if(is.null(avm.svm)|is.null(newdata)){
        stop('model or newdata can not be NULL!!')
    }
    e1071:::predict.svm(avm.svm,newdata = newdata)
}
train.rft<-function(data.train=NULL,formula=NULL,ntree=500){
    if(is.null(data.train)|is.null(formula)){
        stop('data or formula can not be NULL!!')
    }
    randomForest::randomForest(formula,data=data.train, ntree=ntree)
}
pred.rft<-function(avm.rft=NULL,newdata=NULL){
    if(is.null(avm.rft)|is.null(newdata)){
        stop('model or newdata can not be NULL!!')
    }
    randomForest:::predict.randomForest(avm.rft,newdata=newdata)
}
train.xgb<-function(data.train=NULL,formula=NULL,nround=1000){
    if(is.null(data.train)|is.null(formula)){
        stop('data or formula can not be NULL!!')
    }
    twidlr::xgboost(data = data.train,formula = formula,nround=nround, verbose=0)
}
pred.xgb<-function(avm.xgb=NULL,newdata=NULL){
    if(is.null(avm.xgb)|is.null(newdata)){
        stop('model or newdata can not be NULL!!')
    }
    depdent.y.names<-formula(avm.xgb)%>%lhs.vars()
    newdata[,depdent.y.names]<-0
    if(nrow(newdata)==1){
        newdata<-rbind(newdata,newdata)%>%data.frame()
        twidlr:::predict.xgb.Booster(object = avm.xgb,newdata)[1]
    }else{
        twidlr:::predict.xgb.Booster(object = avm.xgb,newdata)
    }

}
# train.gwr<-function(data.train=NULL,formula=NULL,remove.dup=T){
#     if(is.null(data.train)|is.null(formula)){
#         stop('data or formula can not be NULL!!')
#     }
#     library(maptools)
#     rvars<-rhs.vars(formula,data=data.train)
#     rvars.withoutxy<-rvars[rvars!='x'&rvars!='y']
#     formula.gwr.saleprice<-paste(lhs.vars(formula),
#                                  paste(rvars.withoutxy,collapse = '+'),sep='~')%>% as.formula
#     library(spgwr)
#     formula.gwr.saleprice <- log_saleprice ~ hosi.poi.sp_dens + 
#       trans.poi.sp_dens + busi.poi.sp_dens + poi.diversity.pts + 
#       edu.poi.sp_mindist + trans.poi.sp_mindist + busi.poi.sp_mindist
#     data.train <- data.train[which(!duplicated(data.train[7:8])),]
#     GWRbandwidth <- gwr.sel(as.formula(formula.gwr.saleprice), data=data.train, coords=cbind(data.train$x,data.train$y),adapt=T)
#     gwr.model = gwr(as.formula(formula.gwr.saleprice), 
#                     data=data.train, coords=cbind(data.train$x,data.train$y), adapt=GWRbandwidth, hatmatrix=TRUE, se.fit=TRUE)
#     # data.reg.sp<-sp.pts(data_ = data.train%>%na.omit(),remove.dup=remove.dup)
#     # library(GWmodel)
#     # DM<-gw.dist(dp.locat=coordinates(data.reg.sp),longlat = T)
#     # bw1<-bw.gwr(formula.gwr.saleprice, data=data.reg.sp,dMat=DM,longlat = T,approach = 'AIC')
#     # gwr.basic(formula.gwr.saleprice, data=data.reg.sp, bw=bw1,longlat = T,dMat=DM)
# }
# pred.gwr<-function(avm.gwr=NULL,newdata=NULL,retry=10,remove.dup=T){
#     library(GWmodel)
#     data.reg.sp<-avm.gwr$lm$model
#     data.reg.sp$x<-coordinates(avm.gwr$SDF)[,1]
#     data.reg.sp$y<-coordinates(avm.gwr$SDF)[,2]
#     data.reg.sp<-sp.pts(data_ = data.reg.sp,remove.dup=remove.dup)
#     # dependY.raw<-
#     # lhs.vars(avm.gwr$GW.arguments$formula)%>%as.character()%>%str_replace_all('~log\\(|\\)','')
#     # data.reg.sp@data[,dependY.raw]<-exp(data.reg.sp@data[,lhs.vars(avm.gwr$GW.arguments$formula)%>%
#     # as.character()%>%
#     # str_replace('~','')])
#     if(!is(newdata,'Spatial')){
#         newdata<-sp.pts(data_ = newdata,remove.dup=remove.dup)
#     }
#     gwr.pred<-NULL
#     bw.gwr<-avm.gwr$GW.arguments$bw
#     for (i in 1:retry){
#         gwr.pred <- try(
#             gwr.predict(avm.gwr$GW.arguments$formula,
#                         data=data.reg.sp, bw=bw.gwr,
#                         predictdata = newdata,longlat = T), silent=TRUE)
#         if(!is(gwr.pred, 'try-error')) break
#         cat('retrying with an extended bandwidth...','\n')
#         bw.gwr<-bw.gwr/0.618
#     }
# 
#     if(is.null(gwr.pred)){
#         return(NULL)
#     }else{
#         return(gwr.pred$SDF$prediction)
#     }
# }
#' data processing for fitting
#'
#' This function is useful for generating data for fitting
#' @param tabln.vec basic data list generated by \code{\link{loadData}}
#' @param proptype type code of properties.The default values is 11 indicting housing.
#' @param bldg_code type code of building.The default is 11
#' @param var.names.except Variable names which will be exclued in the fitting. See detail
#' @details The default value of var.names.except is \code{c('city_code','proptype','year','month','salecount','rentcount','name','ha_cl_code','ha_cl_name','dist_code','dist_name')}
#' @export
#' @return trainning data for AVM
avm.data.train<-function(tabln.vec=NULL,
                         proptype='11',modelpath1=NULL, city_code=NULL,
                         var.names.except=
                           c('name','ha_cl_code','buildyear','volume_rate','greening_rate',"proptype",
                             'ha_cl_name','dist_code','dist_name','x_',"y_","bldg_code","year","month")){
  ppi_sale<-ppsale(tabln.vec = tabln.vec,proptype = proptype,modelpath1,city_code)
  # ppi_sale$yearmonth<-paste(ppi_sale$year,ppi_sale$month,sep = '-')
  data.train<-ppi_sale%>%dplyr::select(-one_of(var.names.except))
  # data.train[data.train=='NA-NA'] <- NA
  return(data.train)
}

#' @title data spliting
#'
#' @description This function is useful for spliting training and testing data
#' @param data all data sets provided by \code{\link{avm.data.train}}
#' @param train.rate the rate for training. Default value is 0.7, which means 70\% of data will be used in the fitting
#' @export
#' @return a list contain train and test data
data.split<-function(data,train.rate=0.7){
    library(magrittr)
    idx.train<-sample(1:nrow(data),size = nrow(data)*train.rate)%>%sort()
    data.train<-data[idx.train,]
    data.test<-data[-idx.train,]
    list(train=data.train,test=data.test)
}

#' avm prediction function
#'
#' This function will predict according given data
#' @param train.models obejct of models provided by \code{\link{avm.fit}}
#' @param model.list The list of model .The default is \code{list(ols=T,rlm=T,svm=T,rft=T,gwr=T,xgb=T)}
#' @param newdata Testing data or unkown data for prediction. Tesing data is provided by \code{\link{data.split}}
#' @param testing Logic value indicting whether to test.The default is F
#' @param remove.dup Logic variable indicting whether to remove duplicated coordinates.The default is T
#' @return prediction value . It will contain rmse and mae for testing if testing is T
avm.pred<-function(train.models=NULL,
                   model.list=list(ols=T,rlm=T,svm=T,rft=T,xgb=T),
                   newdata=NULL,
                   testing=F,remove.dup=T
                   ){
    if(is.null(train.models)|is.null(newdata)){
        stop('models or newdata can not be NULL!!!!')
    }
    if(testing){
        dependent.name<-(train.models$ols%>%model.frame()%>%colnames())[1]
        dependY.raw<-dependent.name%>%stringr::str_replace_all('log_','')
        sb.idx<-newdata[,dependY.raw]<=0
        actual<-log(newdata[,dependY.raw]+1e-6)
        model.rmse<-vector(mode='list',length = length(model.list) )
        names(model.rmse)<-names(model.list)#c('ols','rlm','svm','rft','xgb')
        model.mae<-model.rmse
        res<-data.frame(y=actual)
    }else{
        res<-data.frame(x=newdata$x,y=newdata$y)
    }
    rvars<-train.models$formula%>%rhs.vars(data=newdata)
    if(is(newdata,'Spatial')){
        newdata@data<-dplyr::select(newdata@data,one_of(rvars))
    }else{
        newdata<-dplyr::select(newdata,one_of(rvars))
    }

    if(model.list$ols){
        # cat('predicting Linear Regression','\n')
        res$ols.pred<-pred.ols(train.models$ols,newdata = newdata)
        if(testing){
            error<-actual-res$ols.pred
            model.rmse$ols<-rmse(error,sb.idx)
            model.mae$ols<-mae(error,sb.idx)
        }
    }
    if(model.list$rlm){
        # cat('predicting Robust Linear Regression','\n')
        res$rlm.pred<-pred.rlm(train.models$rlm,newdata = newdata)
        if(testing){
            error<-actual-res$rlm.pred
            model.rmse$rlm<-rmse(error,sb.idx)
            model.mae$rlm<-mae(error,sb.idx)
        }
    }
    if(model.list$svm){
        # cat('predicting Support Vector Machine','\n')
        res$svm.pred<-pred.svm(train.models$svm,newdata = newdata)
        if(testing){
            error<-actual-res$svm.pred
            model.rmse$svm<-rmse(error,sb.idx)
            model.mae$svm<-mae(error,sb.idx)
        }
    }
    if(model.list$rft){
        # cat('predicting Random Forests','\n')
        res$rft.pred<-pred.rft(train.models$rft,newdata = newdata)
        if(testing){
            error<-actual-res$rft.pred
            model.rmse$rft<-rmse(error,sb.idx)
            model.mae$rft<-mae(error,sb.idx)
        }
    }
    # if(model.list$gwr){
    #     cat('predicting Geographically Weighted Regression','\n')
    #     res$gwr.pred<-pred.gwr(train.models$gwr,newdata = newdata,remove.dup=remove.dup)
    #     if(testing){
    #         error<-actual-res$gwr.pred
    #         model.rmse$gwr<-rmse(error,sb.idx)
    #         model.mae$gwr<-mae(error,sb.idx)
    #     }
    # }
    if(model.list$xgb){
        # cat('predicting eXtreme Gradient Boosting','\n')
        res$xgb.pred<-pred.xgb(train.models$xgb,newdata = newdata)
        if(testing){
            error<-actual-res$xgb.pred
            model.rmse$xgb<-rmse(error,sb.idx)
            model.mae$xgb<-mae(error,sb.idx)
        }
    }
    if(testing){
        model.res<-list(res,model.rmse%>%unlist(),model.mae%>%unlist())
        names(model.res)<-c('pred','rmse','mae')
    }else{
        model.res<-res
    }
    model.res
}

#' generate data for prediction
#'
#' This function will generate data for given data
#' @param train.model object of models provided by \code{\link{avm.fit}},required pameter.
#' @param tabln.vec basic data provided by \code{\link{loadData}}
#' @param poi.data.list data of POI ,required . It will be provided by \code{\link{getpoi.ras}}
#' @param proptype type code of properties.The default is 11 which means housing
#' @param method ols? rlm? svm? rft? xgb?
#' @param x lon,required
#' @param y lat,required
#' @param bldg_code tyep code of building.The default is 11
#' @param byear age of building
#' @param height total floors of building
#' @param floor which floor? The default is 3
#' @param brArea the area? The default is 90
#' @param stru logical
#' @param face_through logical
#' @param face_sun logical
#' @param deco_if logical
#' @param deco_good logical
#' @param prop_rt logical
#' @param byearmin the min byear of a community
#' @param byearmax the max byear of a community
#' @param heightmin the min height of a community
#' @param heightmax the max height of a community
#' @import stringr
#' @export
#' @return data used for predictiong
avm.pred.data<-function(train.model=NULL,
                        tabln.vec=NULL,
                        poi.data.list=NULL,
                        method='ols',
                        proptype='11',
                        x=NULL,
                        y=NULL,
                        bldg_code='11',
                        byear=5,height=18,floor=3,brArea=90,stru=TRUE,face_through=TRUE,
                        face_sun=TRUE,deco_if=TRUE,deco_good=TRUE,prop_rt=TRUE,
                        byearmin=NULL,byearmax=NULL,heightmin=NULL,heightmax=NULL){
  #example: stdcity.avm::avm.pred.data(train.model = models,tabln.vec = tabln.vec,poi.data.list = poi.data.list,
  #                                                       x=120.1776,y=35.94424,bldg_code = '11',height=7,byear=5)

    if(is.null(x)|is.null(y)|is.null(poi.data.list)|is.null(train.model)){
        stop( "coordinates,poidata or train.model can't be NULL")
    }
  
    # calculate byearmin, byearmax
    if (is.null(byearmin)){
      byearmin <- 0
    }
    if (is.null(byearmax)){
      byearmax <- 25
    }
    # calculate heightmin, heightmax
    if (is.null(heightmin)){
      if (bldg_code=='11'){
        heightmin <- 4
      }else if(bldg_code=='12'){
        heightmin <- 9
      }else if(bldg_code=='13'){
        heightmin <- 14
      }else{heightmin <- 1}
    }
    if (is.null(heightmax)){
      if (bldg_code=='11'){
        heightmax <- 8
      }else if(bldg_code=='12'){
        heightmax <- 13
      }else if(bldg_code=='13'){
        heightmax <- 30
      }else{heightmax <- 3}
    }

    pred.xy <- data.frame("bc11"=0,"bc12"=0,"bc13"=0,"bc21"=0,"x"=x,"y"=y)
    xy<-data.frame(x=x,y=y)
    # extract density
    poi.dens.pts<-suppressWarnings(sapply(poi.data.list$poi.dens,raster::extract,y=sp.pts(xy),sp=F))
    poi.dens.pts<-data.frame(t(poi.dens.pts))
    colnames(poi.dens.pts)<-paste0(colnames(poi.dens.pts),'_dens')
    # extract diversity
    poi.diversity.pts<-suppressWarnings(raster::extract(x = poi.data.list$poi.diversity,y=sp.pts(xy),sp=F))
    # extract min distance
    which.poi.sp<-stringr::str_detect(names(tabln.vec),pattern = '\\.poi\\.sp')
    poi.sp.names<-names(tabln.vec)[which.poi.sp]
    poi.mindist<-sapply(X = poi.sp.names, getMindist,ha=sp.pts(xy),list=tabln.vec)
    poi.mindist<-data.frame(t(poi.mindist))
    colnames(poi.mindist)<-paste0(colnames(poi.mindist),'_mindist')
    
    pred.xy<-cbind(pred.xy,poi.dens.pts,poi.diversity.pts,poi.mindist)%>%as.data.frame
    pred.xy[which(names(pred.xy) == paste0("bc",bldg_code))] <- 1
    
    # coeffs <- data.frame("Method"="Value")
    # predict
    if(method=='ols'){
      coeffs <- sapply(train.model, function(train.model,newdata=pred.xy){pred.ols(train.model,newdata)})
    }
    if(method=='rlm'){
      coeffs <- sapply(train.model, function(train.model,newdata=pred.xy){pred.rlm(train.model,newdata)})
    }
    if(method=='svm'){
      coeffs <- sapply(train.model, function(train.model,newdata=pred.xy){pred.svm(train.model,newdata)})
    }
    if(method=='rft'){
      coeffs <- sapply(train.model, function(train.model,newdata=pred.xy){pred.rft(train.model,newdata)})
    }
    # if(model.list$gwr){
    #   cat('predicting Geographically Weighted Regression','\n')
    #   res$gwr.pred<-pred.gwr(train.model$gwr,newdata = newdata,remove.dup=remove.dup)
    # }
    if(method=='xgb'){
      coeffs <- sapply(train.model, function(train.model,newdata=pred.xy){pred.xgb(train.model,newdata)})
    }
    # names(coeffs) <- c("K0","Kbyear","Kheight","Ktime","Kfloor","KbrArea","Kstru","Kface_through","Kface_sun","Kdeco_if","Kdeco_good","Kprop_rt")
    byear <- ifelse(byearmax==byearmin,0,(byear-byearmin)/(byearmax-byearmin))
    height <- ifelse(heightmax==heightmin,0,(height-heightmin)/(heightmax-heightmin))
    res <- coeffs[1] + coeffs[2]*byear + coeffs[3]*height + coeffs[4] + coeffs[5]*(floor-1)/(heightmax-1) + coeffs[6]*log(brArea)/log(500) +
           coeffs[7]*stru + coeffs[8]*face_through + coeffs[9]*face_sun + coeffs[10]*deco_if + coeffs[11]*deco_good + coeffs[12]*prop_rt
    res <- exp(res)
    names(res) <- method
    return(res)
}
#' Prediction for user
#'
#' This function is used for prediction by the user
#' @param city_code the city code 
#' @param train.models object of models provided by \code{\link{avm.fit}},required pameter.
#' @param commodelpath the path storing community models or json files
#' @param tabln.vec basic data provided by \code{\link{loadData}}
#' @param poi.data.list data of POI ,required . It will be provided by \code{\link{getpoi.ras}}
#' @param proptype type code of properties.The default is 11 which means housing
#' @param x lon,required
#' @param y lat,required
#' @param bldg_code tyep code of building.The default is 11
#' @param byear age of building
#' @param height total floors of building
#' @param floor which floor? The default is 3
#' @param brArea the area? The default is 90
#' @param stru logical
#' @param face_through logical
#' @param face_sun logical
#' @param deco_if logical
#' @param deco_good logical
#' @param decoprop_rt logical
#' @param byearmin the min byear of a community
#' @param byearmax the max byear of a community
#' @param heightmin the min height of a community
#' @param heightmax the max height of a community
#' @import stringr
#' @export
#' @return data used for predictiong
user.pred<-function(city_code=NULL,
                        train.models=NULL,
                        commodelpath='.',
                        tabln.vec=NULL,
                        poi.data.list=NULL,
                        proptype='11',
                        x=NULL,
                        y=NULL,
                        bldg_code='11',
                        byear=3,height=6,floor=1,brArea=90,stru=TRUE,face_through=TRUE,
                        face_sun=TRUE,deco_if=TRUE,deco_good=TRUE,prop_rt=TRUE,
                        byearmin=NULL,byearmax=NULL,heightmin=NULL,heightmax=NULL){
  #example: stdcity.avm::avm.pred.data(train.models = models,tabln.vec = tabln.vec,poi.data.list = poi.data.list,
  #                                                       x=120.1776,y=35.94424,bldg_code = '11',height=7,byear=5)
  
  if(is.null(city_code)|is.null(x)|is.null(y)|is.null(poi.data.list)|is.null(train.models)){
    stop( "coordinates,poidata or train.models can't be NULL")
  }
  
  # calculate byearmin, byearmax
  if (is.null(byearmin)){
    byearmin <- 0
  }
  if (is.null(byearmax)){
    byearmax <- 25
  }
  # calculate heightmin, heightmax
  if (is.null(heightmin)){
    if (bldg_code=='11'){
      heightmin <- 4
    }else if(bldg_code=='12'){
      heightmin <- 9
    }else if(bldg_code=='13'){
      heightmin <- 14
    }else{heightmin <- 1}
  }
  if (is.null(heightmax)){
    if (bldg_code=='11'){
      heightmax <- 8
    }else if(bldg_code=='12'){
      heightmax <- 13
    }else if(bldg_code=='13'){
      heightmax <- 30
    }else{heightmax <- 3}
  }
  
  pred.xy <- data.frame("bc11"=0,"bc12"=0,"bc13"=0,"bc21"=0,"x"=x,"y"=y)
  xy<-data.frame(x=x,y=y)
  # extract density
  poi.dens.pts<-suppressWarnings(sapply(poi.data.list$poi.dens,raster::extract,y=sp.pts(xy),sp=F))
  poi.dens.pts<-data.frame(t(poi.dens.pts))
  colnames(poi.dens.pts)<-paste0(colnames(poi.dens.pts),'_dens')
  # extract diversity
  poi.diversity.pts<-suppressWarnings(raster::extract(x = poi.data.list$poi.diversity,y=sp.pts(xy),sp=F))
  # extract min distance
  which.poi.sp<-stringr::str_detect(names(tabln.vec),pattern = '\\.poi\\.sp')
  poi.sp.names<-names(tabln.vec)[which.poi.sp]
  poi.mindist<-sapply(X = poi.sp.names, getMindist,ha=sp.pts(xy),list=tabln.vec)
  poi.mindist<-data.frame(t(poi.mindist))
  colnames(poi.mindist)<-paste0(colnames(poi.mindist),'_mindist')
  
  pred.xy<-cbind(pred.xy,poi.dens.pts,poi.diversity.pts,poi.mindist)%>%as.data.frame
  pred.xy[which(names(pred.xy) == paste0("bc",bldg_code))] <- 1
  
  # coeffs <- data.frame("Method"="Value")
  # predict
  method.set <- train.models$method
  # find the nearest point of method.set to (x,y)
  nearest.idx <- which.min((method.set$x-x)^2+(method.set$y-y)^2)
  method <- method.set[nearest.idx,"model"]
  
  train.model <- train.models[[which(names(train.models)==method)]]
  if(method=='ols'){
    coeffs <- sapply(train.model, function(train.model,newdata=pred.xy){pred.ols(train.model,newdata)})
  }
  if(method=='rlm'){
    coeffs <- sapply(train.model, function(train.model,newdata=pred.xy){pred.rlm(train.model,newdata)})
  }
  if(method=='svm'){
    coeffs <- sapply(train.model, function(train.model,newdata=pred.xy){pred.svm(train.model,newdata)})
  }
  if(method=='rft'){
    coeffs <- sapply(train.model, function(train.model,newdata=pred.xy){pred.rft(train.model,newdata)})
  }
  # if(model.list$gwr){
  #   cat('predicting Geographically Weighted Regression','\n')
  #   res$gwr.pred<-pred.gwr(train.model$gwr,newdata = newdata,remove.dup=remove.dup)
  # }
  if(method=='xgb'){
    coeffs <- sapply(train.model, function(train.model,newdata=pred.xy){pred.xgb(train.model,newdata)})
  }
  # names(coeffs) <- c("K0","Kbyear","Kheight","Ktime","Kfloor","KbrArea","Kstru","Kface_through","Kface_sun","Kdeco_if","Kdeco_good","Kprop_rt")
  byear <- ifelse(byearmax==byearmin,0,(byear-byearmin)/(byearmax-byearmin))
  height <- ifelse(heightmax==heightmin,0,(height-heightmin)/(heightmax-heightmin))
  
  # floor coefficients () transformation
  # datasets with bldg_code
  bldgsets <- subset(tabln.vec$data.sets.all,tabln.vec$data.sets.all[,which(names(tabln.vec$data.sets.all) == paste0("bc",bldg_code))] == 1)
  # find the nearest point of housing area to (x,y)
  nearest.idx <- which.min((bldgsets$x-x)^2+(bldgsets$y-y)^2)
  ha_near <- bldgsets$ha_code[nearest.idx]
  # find the file with the nearest ha_code
  filenames <- list.files(paste0(commodelpath,"/",city_code))
  filepos <- paste0(commodelpath,"/",city_code,"/",filenames)
  file.idx <- which(sapply(sapply(filenames,unlist(strsplit),split="[_]"),function(x) x[1])==ha_near) # extract the ha_code from filesnames
  # read Json
  bldgjson <- fromJSON(file = filepos[file.idx])
  floor_refer <- 0.
  area_refer <- 0.
  if (length(bldgjson)!=0){
    # if existing the bldg_code in the json file
    if (bldg_code %in% names(bldgjson[[1]])){
      bldgfeatures <- bldgjson[[1]][[which(names(bldgjson[[1]])==bldg_code)]]
      features <- bldgfeatures$listFeature
      
      # extract the coefficients of standard variables
      featurenames <- c()
      for (i in 1:length(features))
      {
        featurenames[i] <- features[[i]]$featureName
      }
      
      # calculate the floor_refer
      idflr <- which(featurenames=='floor')
      Kfloor1 <- 0.
      Kfloor <- 0.
      if (length(idflr) > 0){
        for (i in 1:length(idflr))
        {
          if (features[[idflr[i]]]$min==1) {  # the minimum floor value is 1
            idflr_select <- idflr[i]
            Kfloor1 <- features[[idflr_select]]$beta
          }else{Kfloor1 <- 0.}
          if (floor>=features[[idflr[i]]]$min & floor<=features[[idflr[i]]]$max) {  # find the floor group
            idflr_select <- idflr[i]
            Kfloor <- features[[idflr_select]]$beta
            floormin <- features[[idflr_select]]$min
            floormax <- features[[idflr_select]]$max
          } 
        }
        floor_refer <- (coeffs[5]+Kfloor-Kfloor1) * (floor-floormin)/(floormax-floormin)
      }
      
      # calculate the area_refer
      idarea <- which(featurenames=='brArea')
      Karea1 <- 0.
      Karea <- 0.
      if (length(idarea) > 0){
        for (i in 1:length(idarea))
        {
          if (features[[idarea[i]]]$min<90 & features[[idarea[i]]]$max>90) {  # contain area = 90 m^2
            idarea_select <- idarea[i]
            Karea1 <- features[[idarea_select]]$beta
          }else{Karea1 <- 0.}
          if (brArea>=features[[idarea[i]]]$min & brArea<=features[[idarea[i]]]$max) {  # contain area = brArea
            idarea_select <- idarea[i]
            Karea <- features[[idarea_select]]$beta
            areamin <- features[[idarea_select]]$min
            areamax <- features[[idarea_select]]$max
          } 
        }
        area_refer <- (coeffs[6]+Karea-Karea1) * log(brArea)/log(500)
      }
      
    }
  }
  
  res <- coeffs[1] + coeffs[2]*byear + coeffs[3]*height + coeffs[4] + floor_refer + area_refer +
    coeffs[7]*stru + coeffs[8]*face_through + coeffs[9]*face_sun + coeffs[10]*deco_if + coeffs[11]*deco_good + coeffs[12]*prop_rt
  res <- exp(res)
  names(res) <- method
  return(res)
}
# Function that returns Root Mean Squared Error
rmse <- function(error,idx.sb=NULL)
{
    if(!is.null(idx.sb)){
        error[idx.sb]<-NA
    }
    sqrt(mean(error^2,na.rm=T))
}

# Function that returns Mean Absolute Error
mae <- function(error,idx.sb=NULL)
{
    if(!is.null(idx.sb)){
        error[idx.sb]<-NA
    }
    mean(abs(error),na.rm=T)
}

#' This function is used for predicating in all spatial area
#' @param train.models avmmodels made before
#' @param tabln.vec containing community basal information
#' @param poi.data.list containg poi information
#' @param model.list select your models
#' @param data.sets.all all valuable data
#' @return trainning data for AVM
avm.predall<-function(train.models,tabln.vec,poi.data.list,data.sets.all,model.list,bldg_code,remove.dup=T){
  spmin <- log(min(data.sets.all$saleprice)*0.9)
  spmax <- log(max(data.sets.all$saleprice)*1.1)

  if(is.null(train.models)){
    stop('models can not be NULL!!!!')
  }

  newdata <- tabln.vec$ha_info.sp
  # df <- merge(newdata,dplyr::select(data.sets.all,c("ha_code","bc11","bc12","bc13","bc21")),by="ha_code",all.x=TRUE) %>% as.data.frame()
  # df$bc11 <- ifelse(is.na(df$bc11.y),df$bc11.x,df$bc11.y)
  # df$bc12 <- ifelse(is.na(df$bc12.y),df$bc12.x,df$bc12.y)
  # df$bc13 <- ifelse(is.na(df$bc13.y),df$bc13.x,df$bc13.y)
  # df$bc21 <- ifelse(is.na(df$bc21.y),df$bc21.x,df$bc21.y)
  
  newdata@data$bc11 <- 0
  newdata@data$bc12 <- 0
  newdata@data$bc13 <- 0
  newdata@data$bc21 <- 0
  
  newdata@data[,which(names(newdata)==paste0('bc',bldg_code))] <- 1

  newdata <- subset(newdata,select=-c(name,ha_cl_name,ha_cl_code,dist_code,dist_name,
                                      volume_rate,greening_rate)) %>% na.omit()
  
  res<-data.frame(x=newdata$x,y=newdata$y)

  # x variable names
  rvars<-train.models$formula%>%rhs.vars(data=newdata)
  
  if(is(newdata,'Spatial')){
    newdata@data<-dplyr::select(newdata@data,one_of(rvars))
  }else{
    newdata<-dplyr::select(newdata,one_of(rvars))
  }

  if(model.list$ols){
    # cat('predicting Linear Regression','\n')
    res$ols.pred<-pred.ols(train.models$ols,newdata = newdata@data)
  }
  if(model.list$rlm){
    # cat('predicting Robust Linear Regression','\n')
    res$rlm.pred<-pred.rlm(train.models$rlm,newdata = newdata@data)
  }
  if(model.list$svm){
    # cat('predicting Support Vector Machine','\n')
    res$svm.pred<-pred.svm(train.models$svm,newdata = newdata@data)
  }
  if(model.list$rft){
    # cat('predicting Random Forests','\n')
    res$rft.pred<-pred.rft(train.models$rft,newdata = newdata@data)
  }
  # if(model.list$gwr){
  #   cat('predicting Geographically Weighted Regression','\n')
  #   res$gwr.pred<-pred.gwr(train.models$gwr,newdata = newdata,remove.dup=remove.dup)
  # }
  if(model.list$xgb){
    # cat('predicting eXtreme Gradient Boosting','\n')
    res$xgb.pred<-pred.xgb(train.models$xgb,newdata = newdata@data)
  }

  crs3857 <- "+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +wktext  +no_defs"
  resxy <- project(as.matrix(res[1:2]),proj=crs3857)  # class: matrix
  respred <- subset(res,select=-c(x,y))

  resraster <- rasterize(resxy,raster(poi.data.list$poi.dens$edu.poi.sp),field=respred)

  # control the max/in saleprice between (spmin,spmax)
  resraster[resraster>spmax] <- spmax
  resraster[resraster<spmin] <- spmin

  return(resraster)
}


#' This function is used for choosing the best model by the indicator of RMSE
#' @param models avmmodels made before
#' @param testdata test data from data.sets, data.sets$test
#' @param model.list models
#' @export
#' @return the best model
select_model <- function(models,testdata,model.list){
  # actual saleprice, convert to log
  actuals <- log(testdata$saleprice)
  # how many models? (-1), delete the formula dim
  nmodels <- length(models)-1
  # x variable names
  rvars <- models$formula%>%rhs.vars(data=testdata)
  # 
  testdata <- dplyr::select(testdata,one_of(rvars))
  # convert the testdata to dataframe
  # preds<-data.frame("ols.pred"=rep(NA,nrow(testdata)),"rlm.pred"=rep(NA,nrow(testdata)),
  #                   "svm.pred"=rep(NA,nrow(testdata)),"rft.pred"=rep(NA,nrow(testdata)),
  #                   "gwr.pred"=rep(NA,nrow(testdata)),"xgb.pred"=rep(NA,nrow(testdata)))
  preds<-data.frame("ols.pred"=rep(NA,nrow(testdata)),"rlm.pred"=rep(NA,nrow(testdata)),
                    "svm.pred"=rep(NA,nrow(testdata)),"rft.pred"=rep(NA,nrow(testdata)),
                    "xgb.pred"=rep(NA,nrow(testdata)))

  if (model.list$ols) preds$ols.pred <- pred.ols(models$ols,testdata)
  if (model.list$rlm) preds$rlm.pred <- pred.rlm(models$rlm,testdata)
  if (model.list$svm) preds$svm.pred <- pred.svm(models$svm,testdata)
  if (model.list$rft) preds$rft.pred <- pred.rft(models$rft,testdata)
  # if (model.list$gwr) preds$gwr.pred <- pred.gwr(models$gwr,testdata)
  if (model.list$xgb) preds$xgb.pred <- pred.xgb(models$xgb,testdata)
  
  preds <- dplyr::select(preds,paste0(names(model.list[model.list==TRUE]),".pred"))
  
  # calculate the errors
  errors <- preds-actuals
  rmses <- sapply(errors, rmse)
  
  bestmodel <- substr(names(which(rmses==min(rmses))),1,3)
  # cat("The best model is",bestmodel)
  return(bestmodel)
  #
}
